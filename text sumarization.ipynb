{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invalid-while",
   "metadata": {},
   "source": [
    "###### text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "comparative-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Text summarization refers to the technique of shortening long pieces of text. The intention is to create a coherent and fluent summary having only the main points outlined in the document.\n",
    "Automatic text summarization is a common problem in machine learning and natural language processing (NLP).\n",
    "Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.”\n",
    "Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts.\n",
    "What’s the need for text summarization?\n",
    "Propelled by the modern technological innovations, data is to this century what oil was to the previous one. Today, our world is parachuted by the gathering and dissemination of huge amounts of data.\n",
    "In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025. That’s a lot of data!\n",
    "With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages.\n",
    "Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area.\n",
    "What are the main approaches to automatic summarization?\n",
    "There are two main types of how to summarize text in NLP:\n",
    "Extraction-based summarization\n",
    "The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary. The extraction is made according to the defined metric without making any changes to the texts.\n",
    "Here is an example:\n",
    "Source text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem. In the city, Mary gave birth to a child named Jesus.\n",
    "Extractive summary: Joseph and Mary attend event Jerusalem. Mary birth Jesus.\n",
    "As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange.\n",
    "Abstraction-based summarization\n",
    "The abstraction technique entails paraphrasing and shortening parts of the source document. When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method.\n",
    "The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.\n",
    "Therefore, abstraction performs better than extraction. However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular.\n",
    "Here is an example:\n",
    "Abstractive summary: Joseph and Mary came to Jerusalem where Jesus was born.\n",
    "How does a text summarization algorithm work?\n",
    "Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data).\n",
    "Typically, here is how using the extraction-based approach to summarize texts can work:\n",
    "1. Introduce a method to extract the merited keyphrases from the source document. For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases.\n",
    "2. Gather text documents with positively-labeled keyphrases. The keyphrases should be compatible to the stipulated extraction technique. To increase accuracy, you can also create negatively-labeled keyphrases.\n",
    "3. Train a binary machine learning classifier to make the text summarization. Some of the features you can use include:\n",
    "Length of the keyphrase\n",
    "Frequency of the keyphrase\n",
    "The most recurring word in the keyphrase\n",
    "Number of characters in the keyphrase\n",
    "4. Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-infection",
   "metadata": {},
   "source": [
    "### loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "arbitrary-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "every-monster",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP_WORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6a915709676>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# creating the list of stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'STOP_WORDS' is not defined"
     ]
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS) # creating the list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "excellent-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ambient-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text) # getting the text into the nlp for further function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceramic-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Text summarization refers to the technique of shortening long pieces of text. The intention is to create a coherent and fluent summary having only the main points outlined in the document.\n",
       "Automatic text summarization is a common problem in machine learning and natural language processing (NLP).\n",
       "Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.”\n",
       "Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts.\n",
       "What’s the need for text summarization?\n",
       "Propelled by the modern technological innovations, data is to this century what oil was to the previous one. Today, our world is parachuted by the gathering and dissemination of huge amounts of data.\n",
       "In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025. That’s a lot of data!\n",
       "With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages.\n",
       "Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area.\n",
       "What are the main approaches to automatic summarization?\n",
       "There are two main types of how to summarize text in NLP:\n",
       "Extraction-based summarization\n",
       "The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary. The extraction is made according to the defined metric without making any changes to the texts.\n",
       "Here is an example:\n",
       "Source text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem. In the city, Mary gave birth to a child named Jesus.\n",
       "Extractive summary: Joseph and Mary attend event Jerusalem. Mary birth Jesus.\n",
       "As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange.\n",
       "Abstraction-based summarization\n",
       "The abstraction technique entails paraphrasing and shortening parts of the source document. When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method.\n",
       "The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.\n",
       "Therefore, abstraction performs better than extraction. However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular.\n",
       "Here is an example:\n",
       "Abstractive summary: Joseph and Mary came to Jerusalem where Jesus was born.\n",
       "How does a text summarization algorithm work?\n",
       "Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data).\n",
       "Typically, here is how using the extraction-based approach to summarize texts can work:\n",
       "1. Introduce a method to extract the merited keyphrases from the source document. For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases.\n",
       "2. Gather text documents with positively-labeled keyphrases. The keyphrases should be compatible to the stipulated extraction technique. To increase accuracy, you can also create negatively-labeled keyphrases.\n",
       "3. Train a binary machine learning classifier to make the text summarization. Some of the features you can use include:\n",
       "Length of the keyphrase\n",
       "Frequency of the keyphrase\n",
       "The most recurring word in the keyphrase\n",
       "Number of characters in the keyphrase\n",
       "4. Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them.\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-charlotte",
   "metadata": {},
   "source": [
    "### converting the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "boring-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'Text', 'summarization', 'refers', 'to', 'the', 'technique', 'of', 'shortening', 'long', 'pieces', 'of', 'text', '.', 'The', 'intention', 'is', 'to', 'create', 'a', 'coherent', 'and', 'fluent', 'summary', 'having', 'only', 'the', 'main', 'points', 'outlined', 'in', 'the', 'document', '.', '\\n', 'Automatic', 'text', 'summarization', 'is', 'a', 'common', 'problem', 'in', 'machine', 'learning', 'and', 'natural', 'language', 'processing', '(', 'NLP', ')', '.', '\\n', 'Skyhoshi', ',', 'who', 'is', 'a', 'U.S.-based', 'machine', 'learning', 'expert', 'with', '13', 'years', 'of', 'experience', 'and', 'currently', 'teaches', 'people', 'his', 'skills', ',', 'says', 'that', '“', 'the', 'technique', 'has', 'proved', 'to', 'be', 'critical', 'in', 'quickly', 'and', 'accurately', 'summarizing', 'voluminous', 'texts', ',', 'something', 'which', 'could', 'be', 'expensive', 'and', 'time', 'consuming', 'if', 'done', 'without', 'machines', '.', '”', '\\n', 'Machine', 'learning', 'models', 'are', 'usually', 'trained', 'to', 'understand', 'documents', 'and', 'distill', 'the', 'useful', 'information', 'before', 'outputting', 'the', 'required', 'summarized', 'texts', '.', '\\n', 'What', '’s', 'the', 'need', 'for', 'text', 'summarization', '?', '\\n', 'Propelled', 'by', 'the', 'modern', 'technological', 'innovations', ',', 'data', 'is', 'to', 'this', 'century', 'what', 'oil', 'was', 'to', 'the', 'previous', 'one', '.', 'Today', ',', 'our', 'world', 'is', 'parachuted', 'by', 'the', 'gathering', 'and', 'dissemination', 'of', 'huge', 'amounts', 'of', 'data', '.', '\\n', 'In', 'fact', ',', 'the', 'International', 'Data', 'Corporation', '(', 'IDC', ')', 'projects', 'that', 'the', 'total', 'amount', 'of', 'digital', 'data', 'circulating', 'annually', 'around', 'the', 'world', 'would', 'sprout', 'from', '4.4', 'zettabytes', 'in', '2013', 'to', 'hit', '180', 'zettabytes', 'in', '2025', '.', 'That', '’s', 'a', 'lot', 'of', 'data', '!', '\\n', 'With', 'such', 'a', 'big', 'amount', 'of', 'data', 'circulating', 'in', 'the', 'digital', 'space', ',', 'there', 'is', 'need', 'to', 'develop', 'machine', 'learning', 'algorithms', 'that', 'can', 'automatically', 'shorten', 'longer', 'texts', 'and', 'deliver', 'accurate', 'summaries', 'that', 'can', 'fluently', 'pass', 'the', 'intended', 'messages', '.', '\\n', 'Furthermore', ',', 'applying', 'text', 'summarization', 'reduces', 'reading', 'time', ',', 'accelerates', 'the', 'process', 'of', 'researching', 'for', 'information', ',', 'and', 'increases', 'the', 'amount', 'of', 'information', 'that', 'can', 'fit', 'in', 'an', 'area', '.', '\\n', 'What', 'are', 'the', 'main', 'approaches', 'to', 'automatic', 'summarization', '?', '\\n', 'There', 'are', 'two', 'main', 'types', 'of', 'how', 'to', 'summarize', 'text', 'in', 'NLP', ':', '\\n', 'Extraction', '-', 'based', 'summarization', '\\n', 'The', 'extractive', 'text', 'summarization', 'technique', 'involves', 'pulling', 'keyphrases', 'from', 'the', 'source', 'document', 'and', 'combining', 'them', 'to', 'make', 'a', 'summary', '.', 'The', 'extraction', 'is', 'made', 'according', 'to', 'the', 'defined', 'metric', 'without', 'making', 'any', 'changes', 'to', 'the', 'texts', '.', '\\n', 'Here', 'is', 'an', 'example', ':', '\\n', 'Source', 'text', ':', 'Joseph', 'and', 'Mary', 'rode', 'on', 'a', 'donkey', 'to', 'attend', 'the', 'annual', 'event', 'in', 'Jerusalem', '.', 'In', 'the', 'city', ',', 'Mary', 'gave', 'birth', 'to', 'a', 'child', 'named', 'Jesus', '.', '\\n', 'Extractive', 'summary', ':', 'Joseph', 'and', 'Mary', 'attend', 'event', 'Jerusalem', '.', 'Mary', 'birth', 'Jesus', '.', '\\n', 'As', 'you', 'can', 'see', 'above', ',', 'the', 'words', 'in', 'bold', 'have', 'been', 'extracted', 'and', 'joined', 'to', 'create', 'a', 'summary', '—', 'although', 'sometimes', 'the', 'summary', 'can', 'be', 'grammatically', 'strange', '.', '\\n', 'Abstraction', '-', 'based', 'summarization', '\\n', 'The', 'abstraction', 'technique', 'entails', 'paraphrasing', 'and', 'shortening', 'parts', 'of', 'the', 'source', 'document', '.', 'When', 'abstraction', 'is', 'applied', 'for', 'text', 'summarization', 'in', 'deep', 'learning', 'problems', ',', 'it', 'can', 'overcome', 'the', 'grammar', 'inconsistencies', 'of', 'the', 'extractive', 'method', '.', '\\n', 'The', 'abstractive', 'text', 'summarization', 'algorithms', 'create', 'new', 'phrases', 'and', 'sentences', 'that', 'relay', 'the', 'most', 'useful', 'information', 'from', 'the', 'original', 'text', '—', 'just', 'like', 'humans', 'do', '.', '\\n', 'Therefore', ',', 'abstraction', 'performs', 'better', 'than', 'extraction', '.', 'However', ',', 'the', 'text', 'summarization', 'algorithms', 'required', 'to', 'do', 'abstraction', 'are', 'more', 'difficult', 'to', 'develop', ';', 'that', '’s', 'why', 'the', 'use', 'of', 'extraction', 'is', 'still', 'popular', '.', '\\n', 'Here', 'is', 'an', 'example', ':', '\\n', 'Abstractive', 'summary', ':', 'Joseph', 'and', 'Mary', 'came', 'to', 'Jerusalem', 'where', 'Jesus', 'was', 'born', '.', '\\n', 'How', 'does', 'a', 'text', 'summarization', 'algorithm', 'work', '?', '\\n', 'Usually', ',', 'text', 'summarization', 'in', 'NLP', 'is', 'treated', 'as', 'a', 'supervised', 'machine', 'learning', 'problem', '(', 'where', 'future', 'outcomes', 'are', 'predicted', 'based', 'on', 'provided', 'data', ')', '.', '\\n', 'Typically', ',', 'here', 'is', 'how', 'using', 'the', 'extraction', '-', 'based', 'approach', 'to', 'summarize', 'texts', 'can', 'work', ':', '\\n', '1', '.', 'Introduce', 'a', 'method', 'to', 'extract', 'the', 'merited', 'keyphrases', 'from', 'the', 'source', 'document', '.', 'For', 'example', ',', 'you', 'can', 'use', 'part', '-', 'of', '-', 'speech', 'tagging', ',', 'words', 'sequences', ',', 'or', 'other', 'linguistic', 'patterns', 'to', 'identify', 'the', 'keyphrases', '.', '\\n', '2', '.', 'Gather', 'text', 'documents', 'with', 'positively', '-', 'labeled', 'keyphrases', '.', 'The', 'keyphrases', 'should', 'be', 'compatible', 'to', 'the', 'stipulated', 'extraction', 'technique', '.', 'To', 'increase', 'accuracy', ',', 'you', 'can', 'also', 'create', 'negatively', '-', 'labeled', 'keyphrases', '.', '\\n', '3', '.', 'Train', 'a', 'binary', 'machine', 'learning', 'classifier', 'to', 'make', 'the', 'text', 'summarization', '.', 'Some', 'of', 'the', 'features', 'you', 'can', 'use', 'include', ':', '\\n', 'Length', 'of', 'the', 'keyphrase', '\\n', 'Frequency', 'of', 'the', 'keyphrase', '\\n', 'The', 'most', 'recurring', 'word', 'in', 'the', 'keyphrase', '\\n', 'Number', 'of', 'characters', 'in', 'the', 'keyphrase', '\\n', '4', '.', 'Finally', ',', 'in', 'the', 'test', 'phrase', ',', 'create', 'all', 'the', 'keyphrase', 'words', 'and', 'sentences', 'and', 'carry', 'out', 'classification', 'for', 'them', '.', '\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-arthritis",
   "metadata": {},
   "source": [
    "### adding the string of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "floating-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = punctuation + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "twelve-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-narrative",
   "metadata": {},
   "source": [
    "###### finding max occuring word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "scenic-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            #print(word)\n",
    "            if word.text.lower() not in word_freq.keys():\n",
    "                word_freq[word.text.lower()] = 1\n",
    "            else:\n",
    "                word_freq[word.text.lower()] += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "beginning-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 16, 'summarization': 14, 'refers': 1, 'technique': 5, 'shortening': 2, 'long': 1, 'pieces': 1, 'intention': 1, 'create': 5, 'coherent': 1, 'fluent': 1, 'summary': 6, 'having': 1, 'main': 3, 'points': 1, 'outlined': 1, 'document': 4, 'automatic': 2, 'common': 1, 'problem': 2, 'machine': 6, 'learning': 7, 'natural': 1, 'language': 1, 'processing': 1, 'nlp': 3, 'skyhoshi': 1, 'u.s.-based': 1, 'expert': 1, '13': 1, 'years': 1, 'experience': 1, 'currently': 1, 'teaches': 1, 'people': 1, 'skills': 1, 'says': 1, '“': 1, 'proved': 1, 'critical': 1, 'quickly': 1, 'accurately': 1, 'summarizing': 1, 'voluminous': 1, 'texts': 5, 'expensive': 1, 'time': 2, 'consuming': 1, 'machines': 1, '”': 1, 'models': 1, 'usually': 2, 'trained': 1, 'understand': 1, 'documents': 2, 'distill': 1, 'useful': 2, 'information': 4, 'outputting': 1, 'required': 2, 'summarized': 1, 'need': 2, 'propelled': 1, 'modern': 1, 'technological': 1, 'innovations': 1, 'data': 7, 'century': 1, 'oil': 1, 'previous': 1, 'today': 1, 'world': 2, 'parachuted': 1, 'gathering': 1, 'dissemination': 1, 'huge': 1, 'amounts': 1, 'fact': 1, 'international': 1, 'corporation': 1, 'idc': 1, 'projects': 1, 'total': 1, 'digital': 2, 'circulating': 2, 'annually': 1, 'sprout': 1, '4.4': 1, 'zettabytes': 2, '2013': 1, 'hit': 1, '180': 1, '2025': 1, 'lot': 1, 'big': 1, 'space': 1, 'develop': 2, 'algorithms': 3, 'automatically': 1, 'shorten': 1, 'longer': 1, 'deliver': 1, 'accurate': 1, 'summaries': 1, 'fluently': 1, 'pass': 1, 'intended': 1, 'messages': 1, 'furthermore': 1, 'applying': 1, 'reduces': 1, 'reading': 1, 'accelerates': 1, 'process': 1, 'researching': 1, 'increases': 1, 'fit': 1, 'area': 1, 'approaches': 1, 'types': 1, 'summarize': 2, 'extraction': 6, 'based': 4, 'extractive': 3, 'involves': 1, 'pulling': 1, 'keyphrases': 6, 'source': 4, 'combining': 1, 'according': 1, 'defined': 1, 'metric': 1, 'making': 1, 'changes': 1, 'example': 3, 'joseph': 3, 'mary': 5, 'rode': 1, 'donkey': 1, 'attend': 2, 'annual': 1, 'event': 2, 'jerusalem': 3, 'city': 1, 'gave': 1, 'birth': 2, 'child': 1, 'named': 1, 'jesus': 3, 'words': 3, 'bold': 1, 'extracted': 1, 'joined': 1, '—': 2, 'grammatically': 1, 'strange': 1, 'abstraction': 5, 'entails': 1, 'paraphrasing': 1, 'parts': 1, 'applied': 1, 'deep': 1, 'problems': 1, 'overcome': 1, 'grammar': 1, 'inconsistencies': 1, 'method': 2, 'abstractive': 2, 'new': 1, 'phrases': 1, 'sentences': 2, 'relay': 1, 'original': 1, 'like': 1, 'humans': 1, 'performs': 1, 'better': 1, 'difficult': 1, 'use': 3, 'popular': 1, 'came': 1, 'born': 1, 'algorithm': 1, 'work': 2, 'treated': 1, 'supervised': 1, 'future': 1, 'outcomes': 1, 'predicted': 1, 'provided': 1, 'typically': 1, 'approach': 1, '1': 1, 'introduce': 1, 'extract': 1, 'merited': 1, 'speech': 1, 'tagging': 1, 'sequences': 1, 'linguistic': 1, 'patterns': 1, 'identify': 1, '2': 1, 'gather': 1, 'positively': 1, 'labeled': 2, 'compatible': 1, 'stipulated': 1, 'increase': 1, 'accuracy': 1, 'negatively': 1, '3': 1, 'train': 1, 'binary': 1, 'classifier': 1, 'features': 1, 'include': 1, 'length': 1, 'keyphrase': 5, 'frequency': 1, 'recurring': 1, 'word': 1, 'number': 1, 'characters': 1, '4': 1, 'finally': 1, 'test': 1, 'phrase': 1, 'carry': 1, 'classification': 1, '\\n\\n': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-poultry",
   "metadata": {},
   "source": [
    "### finding the max frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "universal-italic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "behavioral-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(word_freq.keys())\n",
    "value_list = list(word_freq.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-texas",
   "metadata": {},
   "source": [
    "### extracting the max frequency word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "consolidated-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 16\n"
     ]
    }
   ],
   "source": [
    "pos = value_list.index(max_freq)\n",
    "print(key_list[pos] ,':', max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-postage",
   "metadata": {},
   "source": [
    "### scaling the words frequency for minmum and maximum (like MinMaxScalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "accurate-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_freq.keys():\n",
    "    word_freq[word] = word_freq[word]/max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "tutorial-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 1.0, 'summarization': 0.875, 'refers': 0.0625, 'technique': 0.3125, 'shortening': 0.125, 'long': 0.0625, 'pieces': 0.0625, 'intention': 0.0625, 'create': 0.3125, 'coherent': 0.0625, 'fluent': 0.0625, 'summary': 0.375, 'having': 0.0625, 'main': 0.1875, 'points': 0.0625, 'outlined': 0.0625, 'document': 0.25, 'automatic': 0.125, 'common': 0.0625, 'problem': 0.125, 'machine': 0.375, 'learning': 0.4375, 'natural': 0.0625, 'language': 0.0625, 'processing': 0.0625, 'nlp': 0.1875, 'skyhoshi': 0.0625, 'u.s.-based': 0.0625, 'expert': 0.0625, '13': 0.0625, 'years': 0.0625, 'experience': 0.0625, 'currently': 0.0625, 'teaches': 0.0625, 'people': 0.0625, 'skills': 0.0625, 'says': 0.0625, '“': 0.0625, 'proved': 0.0625, 'critical': 0.0625, 'quickly': 0.0625, 'accurately': 0.0625, 'summarizing': 0.0625, 'voluminous': 0.0625, 'texts': 0.3125, 'expensive': 0.0625, 'time': 0.125, 'consuming': 0.0625, 'machines': 0.0625, '”': 0.0625, 'models': 0.0625, 'usually': 0.125, 'trained': 0.0625, 'understand': 0.0625, 'documents': 0.125, 'distill': 0.0625, 'useful': 0.125, 'information': 0.25, 'outputting': 0.0625, 'required': 0.125, 'summarized': 0.0625, 'need': 0.125, 'propelled': 0.0625, 'modern': 0.0625, 'technological': 0.0625, 'innovations': 0.0625, 'data': 0.4375, 'century': 0.0625, 'oil': 0.0625, 'previous': 0.0625, 'today': 0.0625, 'world': 0.125, 'parachuted': 0.0625, 'gathering': 0.0625, 'dissemination': 0.0625, 'huge': 0.0625, 'amounts': 0.0625, 'fact': 0.0625, 'international': 0.0625, 'corporation': 0.0625, 'idc': 0.0625, 'projects': 0.0625, 'total': 0.0625, 'digital': 0.125, 'circulating': 0.125, 'annually': 0.0625, 'sprout': 0.0625, '4.4': 0.0625, 'zettabytes': 0.125, '2013': 0.0625, 'hit': 0.0625, '180': 0.0625, '2025': 0.0625, 'lot': 0.0625, 'big': 0.0625, 'space': 0.0625, 'develop': 0.125, 'algorithms': 0.1875, 'automatically': 0.0625, 'shorten': 0.0625, 'longer': 0.0625, 'deliver': 0.0625, 'accurate': 0.0625, 'summaries': 0.0625, 'fluently': 0.0625, 'pass': 0.0625, 'intended': 0.0625, 'messages': 0.0625, 'furthermore': 0.0625, 'applying': 0.0625, 'reduces': 0.0625, 'reading': 0.0625, 'accelerates': 0.0625, 'process': 0.0625, 'researching': 0.0625, 'increases': 0.0625, 'fit': 0.0625, 'area': 0.0625, 'approaches': 0.0625, 'types': 0.0625, 'summarize': 0.125, 'extraction': 0.375, 'based': 0.25, 'extractive': 0.1875, 'involves': 0.0625, 'pulling': 0.0625, 'keyphrases': 0.375, 'source': 0.25, 'combining': 0.0625, 'according': 0.0625, 'defined': 0.0625, 'metric': 0.0625, 'making': 0.0625, 'changes': 0.0625, 'example': 0.1875, 'joseph': 0.1875, 'mary': 0.3125, 'rode': 0.0625, 'donkey': 0.0625, 'attend': 0.125, 'annual': 0.0625, 'event': 0.125, 'jerusalem': 0.1875, 'city': 0.0625, 'gave': 0.0625, 'birth': 0.125, 'child': 0.0625, 'named': 0.0625, 'jesus': 0.1875, 'words': 0.1875, 'bold': 0.0625, 'extracted': 0.0625, 'joined': 0.0625, '—': 0.125, 'grammatically': 0.0625, 'strange': 0.0625, 'abstraction': 0.3125, 'entails': 0.0625, 'paraphrasing': 0.0625, 'parts': 0.0625, 'applied': 0.0625, 'deep': 0.0625, 'problems': 0.0625, 'overcome': 0.0625, 'grammar': 0.0625, 'inconsistencies': 0.0625, 'method': 0.125, 'abstractive': 0.125, 'new': 0.0625, 'phrases': 0.0625, 'sentences': 0.125, 'relay': 0.0625, 'original': 0.0625, 'like': 0.0625, 'humans': 0.0625, 'performs': 0.0625, 'better': 0.0625, 'difficult': 0.0625, 'use': 0.1875, 'popular': 0.0625, 'came': 0.0625, 'born': 0.0625, 'algorithm': 0.0625, 'work': 0.125, 'treated': 0.0625, 'supervised': 0.0625, 'future': 0.0625, 'outcomes': 0.0625, 'predicted': 0.0625, 'provided': 0.0625, 'typically': 0.0625, 'approach': 0.0625, '1': 0.0625, 'introduce': 0.0625, 'extract': 0.0625, 'merited': 0.0625, 'speech': 0.0625, 'tagging': 0.0625, 'sequences': 0.0625, 'linguistic': 0.0625, 'patterns': 0.0625, 'identify': 0.0625, '2': 0.0625, 'gather': 0.0625, 'positively': 0.0625, 'labeled': 0.125, 'compatible': 0.0625, 'stipulated': 0.0625, 'increase': 0.0625, 'accuracy': 0.0625, 'negatively': 0.0625, '3': 0.0625, 'train': 0.0625, 'binary': 0.0625, 'classifier': 0.0625, 'features': 0.0625, 'include': 0.0625, 'length': 0.0625, 'keyphrase': 0.3125, 'frequency': 0.0625, 'recurring': 0.0625, 'word': 0.0625, 'number': 0.0625, 'characters': 0.0625, '4': 0.0625, 'finally': 0.0625, 'test': 0.0625, 'phrase': 0.0625, 'carry': 0.0625, 'classification': 0.0625, '\\n\\n': 0.0625}\n"
     ]
    }
   ],
   "source": [
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-beach",
   "metadata": {},
   "source": [
    "### converting the text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "integrated-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " Text summarization refers to the technique of shortening long pieces of text.,\n",
       " The intention is to create a coherent and fluent summary having only the main points outlined in the document.,\n",
       " \n",
       " Automatic text summarization is a common problem in machine learning and natural language processing (NLP).,\n",
       " ,\n",
       " Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.”,\n",
       " \n",
       " Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts.,\n",
       " ,\n",
       " What’s the need for text summarization?,\n",
       " Propelled by the modern technological innovations, data is to this century what oil was to the previous one.,\n",
       " Today, our world is parachuted by the gathering and dissemination of huge amounts of data.,\n",
       " In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025.,\n",
       " That’s a lot of data!,\n",
       " With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages.,\n",
       " ,\n",
       " Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area.,\n",
       " ,\n",
       " What are the main approaches to automatic summarization?,\n",
       " ,\n",
       " There are two main types of how to summarize text in NLP:\n",
       " Extraction-based summarization,\n",
       " The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary.,\n",
       " The extraction is made according to the defined metric without making any changes to the texts.,\n",
       " ,\n",
       " Here is an example:\n",
       " Source text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem.,\n",
       " In the city, Mary gave birth to a child named Jesus.,\n",
       " ,\n",
       " Extractive summary: Joseph and Mary attend event Jerusalem.,\n",
       " Mary birth Jesus.,\n",
       " ,\n",
       " As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange.,\n",
       " ,\n",
       " Abstraction-based summarization,\n",
       " The abstraction technique entails paraphrasing and shortening parts of the source document.,\n",
       " When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method.,\n",
       " ,\n",
       " The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.,\n",
       " Therefore, abstraction performs better than extraction.,\n",
       " However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular.,\n",
       " ,\n",
       " Here is an example:\n",
       " Abstractive summary: Joseph and Mary came to Jerusalem where Jesus was born.,\n",
       " ,\n",
       " How does a text summarization algorithm work?,\n",
       " ,\n",
       " Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data).,\n",
       " ,\n",
       " Typically, here is how using the extraction-based approach to summarize texts can work:\n",
       " 1.,\n",
       " Introduce a method to extract the merited keyphrases from the source document.,\n",
       " For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases.,\n",
       " ,\n",
       " 2.,\n",
       " Gather text documents with positively-labeled keyphrases.,\n",
       " The keyphrases should be compatible to the stipulated extraction technique.,\n",
       " To increase accuracy, you can also create negatively-labeled keyphrases.,\n",
       " ,\n",
       " 3.,\n",
       " Train a binary machine learning classifier to make the text summarization.,\n",
       " Some of the features you can use include:\n",
       " Length of the keyphrase\n",
       " Frequency of the keyphrase,\n",
       " The most recurring word in the keyphrase\n",
       " Number of characters in the keyphrase\n",
       " 4.,\n",
       " Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them.,\n",
       " \n",
       " ]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [sent for sent in doc.sents]\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-australia",
   "metadata": {},
   "source": [
    "### finding the sentence with max frequency word in it and creating the frequency of the with the other like we did for word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "mounted-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_score = {}\n",
    "for sent in sents:\n",
    "    #print(sent)\n",
    "    for word in sent:\n",
    "        #print(word)\n",
    "        if word.text.lower() in word_freq.keys():\n",
    "            if sent not in sents_score.keys():\n",
    "                sents_score[sent] = word_freq[word.text.lower()]\n",
    "            else:\n",
    "                sents_score[sent] += word_freq[word.text.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "taken-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       " Text summarization refers to the technique of shortening long pieces of text.: 3.5,\n",
       " The intention is to create a coherent and fluent summary having only the main points outlined in the document.: 1.5,\n",
       " \n",
       " Automatic text summarization is a common problem in machine learning and natural language processing (NLP).: 3.375,\n",
       " Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.”: 2.9375,\n",
       " \n",
       " Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts.: 2.25,\n",
       " What’s the need for text summarization?: 2.0,\n",
       " Propelled by the modern technological innovations, data is to this century what oil was to the previous one.: 0.875,\n",
       " Today, our world is parachuted by the gathering and dissemination of huge amounts of data.: 0.9375,\n",
       " In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025.: 2.3125,\n",
       " That’s a lot of data!: 0.5,\n",
       " With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages.: 3.0,\n",
       " Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area.: 3.125,\n",
       " What are the main approaches to automatic summarization?: 1.25,\n",
       " There are two main types of how to summarize text in NLP:\n",
       " Extraction-based summarization: 3.0625,\n",
       " The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary.: 3.8125,\n",
       " The extraction is made according to the defined metric without making any changes to the texts.: 1.0,\n",
       " Here is an example:\n",
       " Source text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem.: 2.5625,\n",
       " In the city, Mary gave birth to a child named Jesus.: 0.875,\n",
       " Extractive summary: Joseph and Mary attend event Jerusalem.: 1.5,\n",
       " Mary birth Jesus.: 0.625,\n",
       " As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange.: 1.6875,\n",
       " Abstraction-based summarization: 1.4375,\n",
       " The abstraction technique entails paraphrasing and shortening parts of the source document.: 1.4375,\n",
       " When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method.: 3.3125,\n",
       " The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.: 4.5,\n",
       " Therefore, abstraction performs better than extraction.: 0.8125,\n",
       " However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular.: 3.3125,\n",
       " Here is an example:\n",
       " Abstractive summary: Joseph and Mary came to Jerusalem where Jesus was born.: 1.6875,\n",
       " How does a text summarization algorithm work?: 2.0625,\n",
       " Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data).: 4.1875,\n",
       " Typically, here is how using the extraction-based approach to summarize texts can work:\n",
       " 1.: 1.375,\n",
       " Introduce a method to extract the merited keyphrases from the source document.: 1.1875,\n",
       " For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases.: 1.3125,\n",
       " 2.: 0.0625,\n",
       " Gather text documents with positively-labeled keyphrases.: 1.75,\n",
       " The keyphrases should be compatible to the stipulated extraction technique.: 1.1875,\n",
       " To increase accuracy, you can also create negatively-labeled keyphrases.: 1.0,\n",
       " 3.: 0.0625,\n",
       " Train a binary machine learning classifier to make the text summarization.: 2.875,\n",
       " Some of the features you can use include:\n",
       " Length of the keyphrase\n",
       " Frequency of the keyphrase: 1.0625,\n",
       " The most recurring word in the keyphrase\n",
       " Number of characters in the keyphrase\n",
       " 4.: 0.9375,\n",
       " Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them.: 1.25,\n",
       " \n",
       " : 0.0625}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-religion",
   "metadata": {},
   "source": [
    "### finding the frequecy with max sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dying-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "stable-reverse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sents)*0.5)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hundred-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.,\n",
       " Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data).,\n",
       " The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary.,\n",
       " \n",
       " Text summarization refers to the technique of shortening long pieces of text.,\n",
       " \n",
       " Automatic text summarization is a common problem in machine learning and natural language processing (NLP).,\n",
       " When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method.,\n",
       " However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular.,\n",
       " Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area.,\n",
       " There are two main types of how to summarize text in NLP:\n",
       " Extraction-based summarization,\n",
       " With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages.,\n",
       " Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.”,\n",
       " Train a binary machine learning classifier to make the text summarization.,\n",
       " Here is an example:\n",
       " Source text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem.,\n",
       " In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025.,\n",
       " \n",
       " Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts.,\n",
       " How does a text summarization algorithm work?,\n",
       " What’s the need for text summarization?,\n",
       " Gather text documents with positively-labeled keyphrases.,\n",
       " As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange.,\n",
       " Here is an example:\n",
       " Abstractive summary: Joseph and Mary came to Jerusalem where Jesus was born.,\n",
       " The intention is to create a coherent and fluent summary having only the main points outlined in the document.,\n",
       " Extractive summary: Joseph and Mary attend event Jerusalem.,\n",
       " Abstraction-based summarization,\n",
       " The abstraction technique entails paraphrasing and shortening parts of the source document.,\n",
       " Typically, here is how using the extraction-based approach to summarize texts can work:\n",
       " 1.,\n",
       " For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases.,\n",
       " What are the main approaches to automatic summarization?,\n",
       " Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them.,\n",
       " Introduce a method to extract the merited keyphrases from the source document.]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = nlargest(select_length, sents_score, key = sents_score.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-damage",
   "metadata": {},
   "source": [
    "### making the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "particular-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_summary = [word.text for word in summary]\n",
    "sumary = ' '.join(total_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "attached-heating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.\\n Usually, text summarization in NLP is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data). The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary. \\nText summarization refers to the technique of shortening long pieces of text. \\nAutomatic text summarization is a common problem in machine learning and natural language processing (NLP). When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method. However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular. Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area. There are two main types of how to summarize text in NLP:\\nExtraction-based summarization\\n With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages. Skyhoshi, who is a U.S.-based machine learning expert with 13 years of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.” Train a binary machine learning classifier to make the text summarization. Here is an example:\\nSource text: Joseph and Mary rode on a donkey to attend the annual event in Jerusalem. In fact, the International Data Corporation (IDC) projects that the total amount of digital data circulating annually around the world would sprout from 4.4 zettabytes in 2013 to hit 180 zettabytes in 2025. \\nMachine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts. How does a text summarization algorithm work? What’s the need for text summarization?\\n Gather text documents with positively-labeled keyphrases. As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange. Here is an example:\\nAbstractive summary: Joseph and Mary came to Jerusalem where Jesus was born. The intention is to create a coherent and fluent summary having only the main points outlined in the document. Extractive summary: Joseph and Mary attend event Jerusalem. Abstraction-based summarization\\n The abstraction technique entails paraphrasing and shortening parts of the source document. Typically, here is how using the extraction-based approach to summarize texts can work:\\n1. For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases. What are the main approaches to automatic summarization? Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them. Introduce a method to extract the merited keyphrases from the source document.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "together-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sumary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-notification",
   "metadata": {},
   "source": [
    "### using the displacy for displaying the words with its info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "green-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "changing-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumary = nlp(sumary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "controlled-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The abstractive text summarization algorithms create new phrases and sentences that relay the most useful information from the original text — just like humans do.</br> Usually, text summarization in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is treated as a supervised machine learning problem (where future outcomes are predicted based on provided data). The extractive text summarization technique involves pulling keyphrases from the source document and combining them to make a summary. </br>Text summarization refers to the technique of shortening long pieces of text. </br>Automatic text summarization is a common problem in machine learning and natural language processing (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "). When abstraction is applied for text summarization in deep learning problems, it can overcome the grammar inconsistencies of the extractive method. However, the text summarization algorithms required to do abstraction are more difficult to develop; that’s why the use of extraction is still popular. Furthermore, applying text summarization reduces reading time, accelerates the process of researching for information, and increases the amount of information that can fit in an area. There are \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " main types of how to summarize text in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ":</br>Extraction-based summarization</br> With such a big amount of data circulating in the digital space, there is need to develop machine learning algorithms that can automatically shorten longer texts and deliver accurate summaries that can fluently pass the intended messages. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Skyhoshi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", who is a U.S.-based machine learning expert with \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    13 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of experience and currently teaches people his skills, says that “the technique has proved to be critical in quickly and accurately summarizing voluminous texts, something which could be expensive and time consuming if done without machines.” Train a binary machine learning classifier to make the text summarization. Here is an example:</br>Source text: \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joseph\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mary\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " rode on a donkey to attend the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    annual\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " event in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jerusalem\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". In fact, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the International Data Corporation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (IDC) projects that the total amount of digital data circulating \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    annually\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " around the world would sprout from \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4.4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " zettabytes in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to hit \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    180\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " zettabytes in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2025\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </br>Machine learning models are usually trained to understand documents and distill the useful information before outputting the required summarized texts. How does a text summarization algorithm work? What’s the need for text summarization?</br> Gather text documents with positively-labeled keyphrases. As you can see above, the words in bold have been extracted and joined to create a summary — although sometimes the summary can be grammatically strange. Here is an example:</br>Abstractive summary: \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joseph\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and Mary came to Jerusalem where Jesus was born. The intention is to create a coherent and fluent summary having only the main points outlined in the document. Extractive summary: \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joseph\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mary\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " attend event \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jerusalem\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Abstraction-based summarization</br> The abstraction technique entails paraphrasing and shortening parts of the source document. Typically, here is how using the extraction-based approach to summarize texts can work:</br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ". For example, you can use part-of-speech tagging, words sequences, or other linguistic patterns to identify the keyphrases. What are the main approaches to automatic summarization? Finally, in the test phrase, create all the keyphrase words and sentences and carry out classification for them. Introduce a method to extract the merited keyphrases from the source document.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sumary,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-courtesy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
